# ì˜ìƒì„ ì°¸ê³ í•´ì„œ ë§Œë“¤ê¸° ì‹œì‘ https://www.youtube.com/watch?v=ZVmLe3odQvc

import streamlit as st
# from langchain_openai import OpenAI
from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI


st.set_page_config(page_title="ê³µê°ì±—", page_icon="ğŸ’¬",
                   layout="wide", initial_sidebar_state="expanded")
st.title("ğŸ’¬ê³µê° ì±—ë´‡ì´ê±¸ë‘~")

# ì„¸ì…˜ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ ì„ ì–¸
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì €ì¥ëœ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
# KoGPT2 ëª¨ë¸ ë¡œë“œ
trained_model = GPT2LMHeadModel.from_pretrained('./kogpt2-chatbot')
trained_tokenizer = PreTrainedTokenizerFast.from_pretrained('./kogpt2-chatbot')
# trained_model = GPT2LMHeadModel.from_pretrained("skt/kogpt2-base-v2")
# trained_tokenizer = PreTrainedTokenizerFast.from_pretrained('skt/kogpt2-base-v2')

# ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ì£¼ëŠ” ì½”ë“œ
def print_message():
    if "messages" in st.session_state and len(st.session_state.messages) > 0:
        for chat_message in st.session_state.messages:
            st.chat_message(chat_message.role).write(chat_message.content)
print_message()


if user_input := st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")
    st.session_state.messages.append(ChatMessage(role="user", content=user_input))
    
    # pre-trained modelì„ ì‚¬ìš©í•´ì„œ ë‹µë³€ ìƒì„±
    # ì…ë ¥ ë¬¸ì¥ í† í°í™”
    # user_input = "ì•ˆë…•"
    input_ids = trained_tokenizer.encode(trained_tokenizer.bos_token + user_input + trained_tokenizer.eos_token, return_tensors='pt')

    # ëª¨ë¸ ì¶”ë¡ 
    outputs = trained_model.generate(input_ids, max_length=50, repetition_penalty=2.0, num_beams=5, early_stopping=True)
    msg = trained_tokenizer.decode(outputs[0], skip_special_tokens=True)
    # print(msg)
    
    # AIì˜ ë‹µë³€
    with st.chat_message("assistant"):
        # msg = f"ì•ˆë…•í•˜ì„¸ìš”! {user_input}ì— ëŒ€í•´ ì•Œë ¤ë“œë¦´ê²Œìš”!"
        st.write(msg)
        st.session_state.messages.append(ChatMessage(role="assistant", content=msg))