# ì˜ìƒì„ ì°¸ê³ í•´ì„œ ë§Œë“¤ê¸° ì‹œì‘ https://www.youtube.com/watch?v=ZVmLe3odQvc

import streamlit as st
from transformers import PreTrainedTokenizerFast, AutoModelForSequenceClassification, GPT2LMHeadModel
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import torch
from peft import LoraConfig, TaskType, get_peft_model

# ---------------------------------------------------------------- #
#%% ì¶”ë¡  ëª¨ë¸ ì¤€ë¹„

cls_peft_config = LoraConfig(
    task_type="SEQ_CLS",
    # inference_mode=False,
    inference_mode=True,
    r=8,
    lora_alpha=32,
    lora_dropout=0.1,
    bias="none")

gen_peft_config = LoraConfig(
    task_type="CAUSAL_LM",
    # inference_mode=False,
    inference_mode=True,
    r=8,
    lora_alpha=32,
    lora_dropout=0.1,
    bias="none")

Q_TKN = "<Q>"
A_TKN = "<A>"
BOS = '</s>'
EOS = '</s>'
UNK = '<unk>'
MASK = '<unused0>'
SENT = '<unused1>'
PAD = '<pad>'

# ì €ì¥ëœ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
cls_path = './models/kogpt2-classification-lora'
cls_model = AutoModelForSequenceClassification.from_pretrained(
      cls_path,
      num_labels=5,
      problem_type="multi_label_classification"
)
trained_cls_model = get_peft_model(cls_model, cls_peft_config)
trained_cls_tokenizer = PreTrainedTokenizerFast.from_pretrained(cls_path)

def predict_listener_empathy(input_text, model, tokenizer, num_classes=5, threshold=0.6):
    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    model.eval()

    # ì…ë ¥ ë¬¸ì¥ í† í°í™”
    inputs = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True, max_length=128)

    # ëª¨ë¸ì— ì…ë ¥ì„ ì „ë‹¬í•˜ì—¬ ë¡œì§“(logits)ì„ ì–»ìŒ
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits

    # ë¡œì§“ì— ì‹œê·¸ëª¨ì´ë“œ ì ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜
    probabilities = torch.sigmoid(logits)
    # ì„ê³„ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ì§„í™”
    predictions = (probabilities > threshold).int()

    # ë ˆì´ë¸” ë””ì½”ë”©
    label_classes = ['ì¡°ì–¸', 'ê²©ë ¤', 'ìœ„ë¡œ', 'ë™ì¡°', '']
    predicted_labels = [label_classes[i] for i in range(num_classes) if predictions[0][i] == 1]

    return predicted_labels

# ì €ì¥ëœ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
gen_path = './models/kogpt2-chatbot'
gen_model = GPT2LMHeadModel.from_pretrained(gen_path)

trained_gen_model = get_peft_model(gen_model, gen_peft_config)
trained_gen_tokenizer = PreTrainedTokenizerFast.from_pretrained(gen_path)

def predict_answer(predicted_labels, input_text, model, tokenizer):
    # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
    model.eval()
    # ì…ë ¥ ë¬¸ì¥ í† í°í™”
    empathy = ' ,'.join(map(str, predicted_labels))
    inputs = Q_TKN + input_text + SENT + empathy + A_TKN
    input_ids = tokenizer.encode(tokenizer.bos_token + inputs + tokenizer.eos_token, return_tensors='pt')

    # ëª¨ë¸ ì¶”ë¡ 
    outputs = model.generate(input_ids, max_length=50, repetition_penalty=2.0, num_beams=5, early_stopping=True)
    output_text = trained_gen_tokenizer.decode(outputs[0], skip_special_tokens=True)

    return output_text

# ---------------------------------------------------------------- #
#%% Streamlit ì•±

st.set_page_config(page_title="ê³µê°ì±—", page_icon="ğŸ’¬")
st.title("ğŸ’¬ê³µê° ì±—ë´‡ì´ê±¸ë‘~")

# ì„¸ì…˜ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ ì„ ì–¸
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì±„íŒ… ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” ì„¸ì…˜ìƒíƒœ ë³€ìˆ˜
if "store" not in st.session_state:
    st.session_state.store = dict()
    
with st.sidebar:
    session_id = st.text_input("ì´ë¦„ì„ ì•Œë ¤ì£¼ì„¸ìš”", value="ex) ì›Œë¼ë°¸")
    
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")
    if clear_btn:
        st.session_state.messages = []
        st.session_state.store = dict()

# ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ì£¼ëŠ” ì½”ë“œ
def print_message():
    if "messages" in st.session_state and len(st.session_state.messages) > 0:
        for chat_message in st.session_state.messages:
            st.chat_message(chat_message.role).write(chat_message.content)
print_message()

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in st.session_state.store:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
        st.session_state.store[session_id] = ChatMessageHistory() # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ê³  storeì— ì €ì¥
    session_history = st.session_state.store[session_id]

    # ë©”ì‹œì§€ ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ nìë¥¼ ë„˜ìœ¼ë©´ ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ì œê±°
    total_length = sum(len(m.content) for m in session_history.messages)
    while total_length > 500 and session_history.messages:
        total_length -= len(session_history.messages[0].content)
        session_history.messages.pop(0)

    return session_history  # ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ChatMessageHistory ê°ì²´ ë°˜í™˜

# ---------------------------------------------------------------- #
#%% ì±—ë´‡ ëŒ€í™” ë¡œì§

if user_input := st.chat_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?"):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")
    st.session_state.messages.append(ChatMessage(role="user", content=user_input))
    
    # ë¶„ë¥˜ ê²°ê³¼ ì¶”ë¡ 
    # threshold ì˜ ì„¤ì •í•´ì•¼
    predicted_labels = predict_listener_empathy(user_input, trained_cls_model, trained_cls_tokenizer, threshold=0.6)

    # ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ì „ì²´ í”„ë¡¬í”„íŠ¸ ìƒì„±
    # session_history = get_session_history(session_id)
    # history_messages = [ChatMessage(role=m.role, content=m.content) for m in session_history.messages]
    # history_messages.append(ChatMessage(role="user", content=user_input))
    # print("history_messages", history_messages)

    # ì‘ë‹µ ìƒì„±
    msg = predict_answer(predicted_labels, user_input, trained_gen_model, trained_gen_tokenizer)
    print("msg", msg)

    # AIì˜ ë‹µë³€
    with st.chat_message("assistant"):
        st.write(msg)
        st.session_state.messages.append(ChatMessage(role="assistant", content=msg))
        # ì„¸ì…˜ ê¸°ë¡ì— AIì˜ ì‘ë‹µ ì¶”ê°€
        # session_history.add_message(ChatMessage(role="assistant", content=msg))
        # print("history_messages", session_history)
    